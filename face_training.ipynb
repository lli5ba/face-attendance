{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"-- load images, scale, store in tensor...\"]:28: unexpected symbol near ':'",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"-- load images, scale, store in tensor...\"]:28: unexpected symbol near ':'"
     ]
    }
   ],
   "source": [
    "-- load images, scale, store in tensor\n",
    "\n",
    "\n",
    "-- make labels\n",
    "\n",
    "\n",
    "--Load the AlexNet model\n",
    "alexnet = torch.load('alexnetowtbn_epoch55_cpu.t7')\n",
    "alexnet:evaluate()\n",
    "\n",
    "-- Pre-process the image channel by channel.\n",
    "function preprocess(im)\n",
    "    local output_image = image.scale(im:clone(), 224, 224)\n",
    "    for i = 1, 3 do -- channels\n",
    "        output_image[{{i},{},{}}]:add(-meanStd.mean[i])\n",
    "        output_image[{{i},{},{}}]:div(meanStd.std[i])\n",
    "    end\n",
    "    return output_image\n",
    "end\n",
    "\n",
    "--Get fc6 output given a model and input image\n",
    "function fc6output(model, im)\n",
    "    \n",
    "    \n",
    "\n",
    "--Build linear model (takes 2(4096))\n",
    "--run \"linearmodel:forward({x, y})\", x and y are fc6outputs\n",
    "function build_linear_model():\n",
    "    local linearmodel = nn.Sequential()\n",
    "    linearmodel:add(nn.PairwiseDistance(2))\n",
    "    linearmodel:add(nn.Linear(4096,512))\n",
    "    linearmodel:add(nn.Linear(512, 1))\n",
    "    return linearmodel\n",
    "\n",
    "function predict(model, img_a, img_b):\n",
    "    fc6_a = fc6output(alexnet, img_a)\n",
    "    fc6_b = fc6output(alexnet, img_b)\n",
    "    model:forward({fc6_b})\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "\n",
    "--Load the AlexNet model\n",
    "meanStd = torch.load('alexnetowtbn_meanStd.t7')\n",
    "alexnet = torch.load('alexnetowtbn_epoch55_cpu.t7')\n",
    "alexnet:evaluate()\n",
    "\n",
    "\n",
    "-- Pre-process the image channel by channel.\n",
    "function preprocess(im)\n",
    "    local output_image = image.scale(im:clone(), 224, 224)\n",
    "    for i = 1, 3 do -- channels\n",
    "        output_image[{{i},{},{}}]:add(-meanStd.mean[i])\n",
    "        output_image[{{i},{},{}}]:div(meanStd.std[i])\n",
    "    end\n",
    "    return output_image\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function extract_fc6(input_image)\n",
    "    input_image = image.scale(input_image, 224, 224)\n",
    "    -- itorch.image(input_image)\n",
    "    input_image = preprocess(input_image):view(1, 3, 224, 224)\n",
    "    local predictions = alexnet:forward(input_image)\n",
    "    -- print(predictions)\n",
    "    return alexnet:get(2):get(3).output\n",
    "end\n",
    "\n",
    "\n",
    "linearmodel = nn.Sequential()\n",
    "linearmodel:add(nn.Linear(8192,512))\n",
    "linearmodel:add(nn.Linear(512, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- TODO: need to change BCECriterion\n",
    "local criterion = nn.BCECriterion() -- Negative log-likelihood criterion.\n",
    "-- params is a flat vector with the concatenation of all the parameters inside model.\n",
    "-- gradParams is a flat vector with the concatenation of all the gradients of parameters inside the model.\n",
    "-- These two variables also merely point to the internal individual parameters in each layer of the module.\n",
    "\n",
    "function trainModel(model, opt, features, preprocessFn)\n",
    "    -- Get all the parameters (and gradients) of the model in a single vector.\n",
    "    local params, gradParams = model:getParameters()\n",
    "\n",
    "    local opt = opt or {}\n",
    "    local batchSize = opt.batchSize or 64  -- The bigger the batch size the most accurate the gradients.\n",
    "    local learningRate = opt.learningRate or 0.001  -- This is the learning rate parameter often referred to as lambda.\n",
    "    local momentumRate = opt.momentumRate or 0.9\n",
    "    local numEpochs = opt.numEpochs or 3\n",
    "    local velocityParams = torch.zeros(gradParams:size())\n",
    "    local train_features, val_features\n",
    "    -- TODO: need to remove those!!\n",
    "    if preprocessFn then\n",
    "        train_features = trainset.data:float():div(255)\n",
    "        val_features = valset.data:float():div(255)\n",
    "    else\n",
    "        train_features = (features and features.train_features) or trainset.normdata\n",
    "        val_features = (features and features.val_features) or valset.normdata\n",
    "    end\n",
    "    -- Go over the training data this number of times.\n",
    "    for epoch = 1, numEpochs do\n",
    "        local sum_loss = 0\n",
    "        local correct = 0\n",
    "        \n",
    "        -- Run over the training set samples.\n",
    "        -- set internal var Train=True so that layers like Dropout behave correctly. Also see :evaluate()\n",
    "        model:training()\n",
    "        for i = 1, trainset.normdata:size(1) / batchSize do\n",
    "            \n",
    "            -- 1. Sample a batch.\n",
    "            local inputs\n",
    "            if preprocessFn then\n",
    "                inputs = torch.Tensor(batchSize, 3, 224, 224)\n",
    "            else\n",
    "                inputs = (features and torch.Tensor(batchSize, 4096)) or torch.Tensor(batchSize, 3, 32, 32)\n",
    "            end\n",
    "            local labels = torch.Tensor(batchSize)\n",
    "            for bi = 1, batchSize do\n",
    "                local rand_id = torch.random(1, train_features:size(1))\n",
    "                if preprocessFn then\n",
    "                    inputs[bi] = preprocessFn(train_features[rand_id])\n",
    "                else\n",
    "                    inputs[bi] = train_features[rand_id]\n",
    "                end\n",
    "                labels[bi] = trainset.label[rand_id]\n",
    "            end\n",
    "            -- 2. Perform the forward pass (prediction mode).\n",
    "            local predictions = model:forward(inputs)\n",
    "            \n",
    "            -- 3. Evaluate results.\n",
    "            for i = 1, predictions:size(1) do\n",
    "                local _, predicted_label = predictions[i]:max(1)\n",
    "                if predicted_label[1] == labels[i] then correct = correct + 1 end\n",
    "            end\n",
    "            sum_loss = sum_loss + criterion:forward(predictions, labels)\n",
    "            \n",
    "            -- TODO: need to figure out how to change this to accomandate the BCECriterion\n",
    "            -- 4. Perform the backward pass (compute derivatives).\n",
    "            -- This zeroes-out all the parameters inside the model pointed by variable params.\n",
    "            model:zeroGradParameters()\n",
    "            -- This internally computes the gradients with respect to the parameters pointed by gradParams.\n",
    "            local gradPredictions = criterion:backward(predictions, labels)\n",
    "            model:backward(inputs, gradPredictions)\n",
    "\n",
    "            -- 5. Perform the SGD update.\n",
    "            velocityParams:mul(momentumRate)\n",
    "            velocityParams:add(learningRate, gradParams)\n",
    "            params:add(-1, velocityParams)\n",
    "\n",
    "            if i % 100 == 0 then  -- Print this every five thousand iterations.\n",
    "                print(('train epoch=%d, iteration=%d, avg-loss=%.6f, avg-accuracy = %.2f')\n",
    "                    :format(epoch, i, sum_loss / i, correct / (i * batchSize)))\n",
    "            end\n",
    "        end\n",
    "\n",
    "        -- Run over the validation set for evaluation.\n",
    "        local validation_accuracy = 0\n",
    "        local nBatches = val_features:size(1) / batchSize\n",
    "        model:evaluate()\n",
    "        for i = 1, nBatches do\n",
    "            \n",
    "            -- 1. Sample a batch.\n",
    "            if preprocessFn then\n",
    "                inputs = torch.Tensor(batchSize, 3, 224, 224)\n",
    "            else\n",
    "                inputs = (features and torch.Tensor(batchSize, 4096)) or torch.Tensor(batchSize, 3, 32, 32)\n",
    "            end\n",
    "            local labels = torch.Tensor(batchSize)\n",
    "            for bi = 1, batchSize do\n",
    "                local rand_id = torch.random(1, val_features:size(1))\n",
    "                if preprocessFn then\n",
    "                    inputs[bi] = preprocessFn(val_features[rand_id])\n",
    "                else\n",
    "                    inputs[bi] = val_features[rand_id]\n",
    "                end\n",
    "                labels[bi] = valset.label[rand_id]\n",
    "            end\n",
    "\n",
    "            -- 2. Perform the forward pass (prediction mode).\n",
    "            local predictions = model:forward(inputs)\n",
    "            \n",
    "            -- 3. evaluate results.\n",
    "            for i = 1, predictions:size(1) do\n",
    "                local _, predicted_label = predictions[i]:max(1)\n",
    "                if predicted_label[1] == labels[i] then validation_accuracy = validation_accuracy + 1 end\n",
    "            end\n",
    "        end\n",
    "        validation_accuracy = validation_accuracy / (nBatches * batchSize)\n",
    "        print(('\\nvalidation accuracy at epoch = %d is %.4f'):format(epoch, validation_accuracy))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.1189\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local input_image1 = extract_fc6(image.load('test.jpg', 3, 'float')):double()\n",
    "local input_image2 = extract_fc6(image.load('test2.jpg', 3, 'float')):double()\n",
    "local cat_input_image = torch.cat(input_image1, input_image2)\n",
    "local response = linearmodel:forward(cat_input_image)\n",
    "print(response)\n",
    "-- print(extract_fc6(input_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
